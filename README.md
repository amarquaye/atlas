# ATLAS

Final year project by [Jesse Amarquaye](mailto:jesseamarquayelegendary@gmail.com "Send email") and Greatman Akomea, computer engineering students from [Ghana Communication Technology University](https://www.gctu.edu.gh "GCTU").

## Table Of Contents

- [Introduction](#introduction)
  - [Why work on hallucination in LLMs?](#why-work-on-hallucination-in-llms)

## Introduction

Atlas is a hallucination detector for Large Language Models.
Its main focus is on **generative text** as it is the most widely used medium of interacting with LLMs.

### Why work on hallucination in LLMs?

Large language models (LLMs) are revolutionizing human-computer interaction, generating increasingly *fluent* and *human-like text*. However, a significant challenge in LLMs is their tendency to produce **hallucinations**, or factually incorrect, nonsensical, or misleading content. As humans become increasingly reliant on LLMs for information and decision-making, ensuring their reliability and accuracy is crucial. This project aims to address this challenge by developing a software for **detecting** and **mitigating** hallucinations in LLMs.
